{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "import re\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/SMSSpamCollection', sep='\\t', names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(df['message'], df['label'], test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "NON_ALPHANUM = re.compile(r'[\\W]')\n",
    "NON_ASCII = re.compile(r'[^a-z0-1\\s]')\n",
    "def normalize_texts(texts):\n",
    "    normalized_texts = []\n",
    "    for text in texts:\n",
    "        lower = text.lower()\n",
    "        no_punctuation = NON_ALPHANUM.sub(r' ', lower)\n",
    "        no_non_ascii = NON_ASCII.sub(r'', no_punctuation)\n",
    "        normalized_texts.append(no_non_ascii)\n",
    "    return normalized_texts\n",
    "        \n",
    "train_texts = normalize_texts(train_texts.tolist())\n",
    "val_texts = normalize_texts(val_texts.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 1200\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "train_texts = tokenizer.texts_to_sequences(train_texts)\n",
    "val_texts = tokenizer.texts_to_sequences(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = max(len(train_ex) for train_ex in train_texts)\n",
    "MAX_LENGTH = 32\n",
    "train_texts = pad_sequences(train_texts, maxlen=MAX_LENGTH, padding='post')\n",
    "val_texts = pad_sequences(val_texts, maxlen=MAX_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.map(lambda x : 0 if x == 'ham' else 1)\n",
    "val_labels = val_labels.map(lambda x : 0 if x == 'ham' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 24, input_length=MAX_LENGTH))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 0.0458 - val_accuracy: 0.9892\n",
      "Epoch 2/2\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0609 - val_accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2e45ce445e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_texts,\n",
    "          train_labels, \n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          validation_data=(val_texts, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.988\n",
      "F1 score: 0.9507\n",
      "ROC AUC score: 0.9902\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(val_texts)\n",
    "print('Accuracy score: {:0.4}'.format(accuracy_score(val_labels, 1 * (preds > 0.5))))\n",
    "print('F1 score: {:0.4}'.format(f1_score(val_labels, 1 * (preds > 0.5))))\n",
    "print('ROC AUC score: {:0.4}'.format(roc_auc_score(val_labels, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(val):\n",
    "    val = normalize_texts([val])\n",
    "    val = tokenizer.texts_to_sequences(val)\n",
    "    val = pad_sequences(val, maxlen=MAX_LENGTH)\n",
    "    print(model.predict(val)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A gram usually runs like  &lt;#&gt; , a half eighth is smarter though and gets you almost a whole second gram for  &lt;#&gt;'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']=='ham'].iloc[41]['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.19081915e-05]\n"
     ]
    }
   ],
   "source": [
    "pred('A gram usually runs like  &lt;#&gt; , a half eighth is smarter though and gets you almost a whole second gram for  &lt;#&gt;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1460\n",
      "           1       0.99      0.91      0.95       212\n",
      "\n",
      "    accuracy                           0.99      1672\n",
      "   macro avg       0.99      0.95      0.97      1672\n",
      "weighted avg       0.99      0.99      0.99      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_labels, 1 * (preds > 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Assets/spam_detector.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../Assets/spam-tokenizer-5.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../Assets/spam-tokenizer-4.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
